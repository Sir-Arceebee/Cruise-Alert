<!DOCTYPE html>
<html>
  <head>
    <meta charset="UTF-8" />
    <title>Sleep Detection</title>
    {% load static %}
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
  </head>
  <body>
    <h1>Sleep Detection</h1>

    <canvas id="canvas" width="640" height="480"></canvas>
    <p id="status">Status: Awake</p>

    <button id="start">Start Detection</button>
    <button id="stop">Stop Detection</button>

    <!-- CSRF token hidden input -->
    <input type="hidden" id="csrf-token" value="{{ csrf_token }}" />

    <script>
      const canvas = document.getElementById("canvas");
      const startButton = document.getElementById("start");
      const stopButton = document.getElementById("stop");
      const statusText = document.getElementById("status");
      const csrfToken = document.getElementById("csrf-token").value; // Get CSRF token value

      let stream;
      let animationFrameId;
      const video = document.createElement("video");

      async function startCamera() {
        try {
          stream = await navigator.mediaDevices.getUserMedia({ video: true });
          video.srcObject = stream;
          await video.play();

          await faceapi.nets.tinyFaceDetector.loadFromUri("/models");
          await faceapi.nets.faceLandmark68Net.loadFromUri("/models");

          detectFaces();
        } catch (err) {
          console.error("Error accessing the camera: ", err);
        }
      }

      function stopCamera() {
        if (stream) {
          const tracks = stream.getTracks();
          tracks.forEach((track) => track.stop());
        }
        cancelAnimationFrame(animationFrameId);
      }

      async function detectFaces() {
        const context = canvas.getContext("2d");
        context.clearRect(0, 0, canvas.width, canvas.height); // Clear previous drawings
        context.drawImage(video, 0, 0, canvas.width, canvas.height);

        const detections = await faceapi
          .detectAllFaces(video, new faceapi.TinyFaceDetectorOptions())
          .withFaceLandmarks();
        detections.forEach((detection) => {
          const landmarks = detection.landmarks;
          const leftEye = landmarks.getLeftEye();
          const rightEye = landmarks.getRightEye();
          drawEyesOnCanvas(leftEye, rightEye);
        });

        animationFrameId = requestAnimationFrame(detectFaces);
      }

      function drawEyesOnCanvas(leftEye, rightEye) {
        const context = canvas.getContext("2d");

        // Draw left eye box
        if (leftEye && leftEye.length > 0) {
          context.beginPath();
          leftEye.forEach((point, index) => {
            if (index === 0) {
              context.moveTo(point.x, point.y);
            } else {
              context.lineTo(point.x, point.y);
            }
          });
          context.closePath();
          context.strokeStyle = "green";
          context.lineWidth = 2;
          context.stroke();
        }

        // Draw right eye box
        if (rightEye && rightEye.length > 0) {
          context.beginPath();
          rightEye.forEach((point, index) => {
            if (index === 0) {
              context.moveTo(point.x, point.y);
            } else {
              context.lineTo(point.x, point.y);
            }
          });
          context.closePath();
          context.strokeStyle = "green";
          context.lineWidth = 2;
          context.stroke();
        }
      }

      startButton.addEventListener("click", () => {
        startCamera();
      });

      stopButton.addEventListener("click", () => {
        stopCamera();
      });
    </script>
  </body>
</html>
